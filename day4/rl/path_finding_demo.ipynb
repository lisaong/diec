{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "path_finding_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM43NWgCORz4olMgoJ1X1SZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaong/diec/blob/rl_path_finding/day4/rl/path_finding_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxsIdZTi60PM",
        "colab_type": "text"
      },
      "source": [
        "# Reinforcement Learning Path-Finding Demo\n",
        "\n",
        "This demonstrates how to:\n",
        "- Use OpenAI gym to create a custom environment\n",
        "- Compare different Q-learning algorithms for Reinforcement Learning\n",
        "\n",
        "Inspired by: http://mnemstudio.org/path-finding-q-learning-tutorial.htm\n",
        "\n",
        "## Problem Setup\n",
        "\n",
        "Bender is lost in Fry's house! Help Bender find Fry (who is in Room 5 waiting with a can of beer).\n",
        "\n",
        "![intro](https://github.com/lisaong/diec/raw/rl_path_finding/day4/rl/path_finding_intro.png)\n",
        "\n",
        "## OpenAI Gym\n",
        "\n",
        "[OpenAI Gym](https://gym.openai.com/) is an open-source Python toolkit for developing RL algorithms.\n",
        "\n",
        "We will use OpenAI gym to re-create Fry's house, then run some reinforcement learning to find the path.\n",
        "\n",
        "https://github.com/openai/gym/blob/master/docs/creating-environments.md\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvDQ9PwW6SFZ",
        "colab_type": "code",
        "outputId": "f87f8df8-d0eb-4c42-d516-9ff3a2fb9d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# gym is already built into Colab\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "gym.__version__"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.15.6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GBlQwqV_dSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# A Simple Path Finding OpenAI Gym Environment\n",
        "#\n",
        "# Inspired by: http://mnemstudio.org/path-finding-q-learning-tutorial.htm\n",
        "#\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class FrysHomeEnv(gym.Env):\n",
        "  \"\"\"Custom Environment describing Fry's home  \n",
        "  \n",
        "  For details on the gym.Env class:\n",
        "  https://github.com/openai/gym/blob/master/gym/core.py\n",
        "  \"\"\"\n",
        "\n",
        "  # render to the current display or terminal\n",
        "  metadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self, rewards):\n",
        "    super(FrysHomeEnv, self).__init__()\n",
        "\n",
        "    self.rewards = rewards\n",
        "    self.num_rooms = self.rewards.shape[0]\n",
        "\n",
        "    # Action space describes all possible actions that can be taken\n",
        "    # here, we can select 1 out of 6 rooms\n",
        "    self.action_space = spaces.Discrete(self.num_rooms)\n",
        "\n",
        "    # Observation space describes the valid observations\n",
        "    # since we are moving between rooms, we can be in 1 of 6 rooms\n",
        "    self.observation_space = spaces.Discrete(self.num_rooms)\n",
        "\n",
        "    # Rewards range describes the min and max possible rewards\n",
        "    self.reward_range = (self.rewards.min(), self.rewards.max())\n",
        "\n",
        "    # Room 5 is our goal\n",
        "    self.goal = 5\n",
        "\n",
        "    # Initialise our state\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Reset the environment to an initial state\"\"\"\n",
        "\n",
        "    # Randomly initialise the state\n",
        "    self.state = random.randint(0, self.num_rooms-1)\n",
        "\n",
        "    # Return the observation (same as the state in our case)\n",
        "    obs = self.state\n",
        "    return obs\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Execute one step within the environment\"\"\"\n",
        "\n",
        "    # take the selected action\n",
        "    prev_state = self.state\n",
        "    self.state = action\n",
        "\n",
        "    # calculate the reward\n",
        "    reward = self.rewards[prev_state][action]\n",
        "\n",
        "    # check if we've reached our goal\n",
        "    done = (prev_state == self.goal or self.state == self.goal)\n",
        "\n",
        "    # get the next observation\n",
        "    obs = self.state\n",
        "\n",
        "    return obs, reward, done, {}\n",
        "\n",
        "  def render(self, mode='human', close=True):\n",
        "    \"\"\"Print state of the current environment\"\"\"\n",
        "    print(f'Current room: {self.state}, Reached goal: {self.state == self.goal}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyjONcEzEzTj",
        "colab_type": "code",
        "outputId": "e93380b5-d60a-4581-b91a-49634e62eb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Unit testing\n",
        "\n",
        "# Initialise the rewards matrix for the rooms in the house\n",
        "# Where:\n",
        "#  state: current room, action: next room\n",
        "#  dimensions (row=state, col=actions)\n",
        "#  A value of -1 means there is no adjacent path from room_i to room_j\n",
        "#  (for example, room_0 to room_0 has, room_0 to room_5)\n",
        "R = np.array([[-1, -1, -1, -1,  0, -1], # action 0\n",
        "              [-1, -1, -1,  0, -1, 0],  # action 1\n",
        "              [-1, -1, -1,  0, -1, -1], # etc\n",
        "              [-1,  0,  0, -1,  0, -1],\n",
        "              [ 0, -1, -1,  0, -1,  0],\n",
        "              [-1, 100, -1, -1, 100, 100]])\n",
        "\n",
        "myenv = FrysHomeEnv(rewards=R)\n",
        "\n",
        "for i in range(0, 6):\n",
        "  print(myenv.step(i))\n",
        "  myenv.render()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, -1, True, {})\n",
            "Current room: 0, Reached goal: False\n",
            "(1, -1, False, {})\n",
            "Current room: 1, Reached goal: False\n",
            "(2, -1, False, {})\n",
            "Current room: 2, Reached goal: False\n",
            "(3, 0, False, {})\n",
            "Current room: 3, Reached goal: False\n",
            "(4, 0, False, {})\n",
            "Current room: 4, Reached goal: False\n",
            "(5, 0, True, {})\n",
            "Current room: 5, Reached goal: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ8RA_ilKtkX",
        "colab_type": "text"
      },
      "source": [
        "## Package custom environment as module\n",
        "\n",
        "OpenAI gym requires all environments to be packaged as Python modules.\n",
        "\n",
        "The code above has been packaged here:\n",
        "https://github.com/lisaong/diec/blob/master/day4/rl/gym-fryshome\n",
        "\n",
        "The module follows this convention:\n",
        "https://github.com/openai/gym/blob/master/docs/creating-environments.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBhgYzDkN46S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ded5eeee-80c1-4346-8b85-059aa457379e"
      },
      "source": [
        "!git clone -b rl_path_finding https://github.com/lisaong/diec.git\n",
        "%cd diec/day4/rl/gym-fryshome\n",
        "!git pull\n",
        "!pip install --verbose -e  ."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'diec' already exists and is not an empty directory.\n",
            "/content/diec/day4/rl/gym-fryshome\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 17 (delta 11), reused 12 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "From https://github.com/lisaong/diec\n",
            "   f52e36d..b8d2558  rl_path_finding -> origin/rl_path_finding\n",
            "Updating f52e36d..b8d2558\n",
            "Fast-forward\n",
            " .../gym_fryshome/envs/frys_home_env.py             |  16 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " day4/rl/path_finding_demo.ipynb                    | 254 \u001b[32m++++++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " 2 files changed, 144 insertions(+), 126 deletions(-)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-39sk297y\n",
            "Created temporary directory: /tmp/pip-req-tracker-w83an5vv\n",
            "Created requirements tracker '/tmp/pip-req-tracker-w83an5vv'\n",
            "Created temporary directory: /tmp/pip-install-883a0bjx\n",
            "Obtaining file:///content/diec/day4/rl/gym-fryshome\n",
            "  Added file:///content/diec/day4/rl/gym-fryshome to build tracker '/tmp/pip-req-tracker-w83an5vv'\n",
            "    Running setup.py (path:/content/diec/day4/rl/gym-fryshome/setup.py) egg_info for package from file:///content/diec/day4/rl/gym-fryshome\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    writing gym_fryshome.egg-info/PKG-INFO\n",
            "    writing dependency_links to gym_fryshome.egg-info/dependency_links.txt\n",
            "    writing requirements to gym_fryshome.egg-info/requires.txt\n",
            "    writing top-level names to gym_fryshome.egg-info/top_level.txt\n",
            "    writing manifest file 'gym_fryshome.egg-info/SOURCES.txt'\n",
            "  Source in /content/diec/day4/rl/gym-fryshome has version 0.0.1, which satisfies requirement gym-fryshome==0.0.1 from file:///content/diec/day4/rl/gym-fryshome\n",
            "  Removed gym-fryshome==0.0.1 from file:///content/diec/day4/rl/gym-fryshome from build tracker '/tmp/pip-req-tracker-w83an5vv'\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-fryshome==0.0.1) (0.15.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gym-fryshome==0.0.1) (1.17.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-fryshome==0.0.1) (1.4.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym->gym-fryshome==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-fryshome==0.0.1) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-fryshome==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-fryshome==0.0.1) (0.16.0)\n",
            "Installing collected packages: gym-fryshome\n",
            "  Found existing installation: gym-fryshome 0.0.1\n",
            "    Not sure how to uninstall: gym-fryshome 0.0.1 - Check: /content/diec/day4/rl/gym-fryshome\n",
            "    Can't uninstall 'gym-fryshome'. No files were found to uninstall.\n",
            "  Running setup.py develop for gym-fryshome\n",
            "    Running command /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/diec/day4/rl/gym-fryshome/setup.py'\"'\"'; __file__='\"'\"'/content/diec/day4/rl/gym-fryshome/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    writing gym_fryshome.egg-info/PKG-INFO\n",
            "    writing dependency_links to gym_fryshome.egg-info/dependency_links.txt\n",
            "    writing requirements to gym_fryshome.egg-info/requires.txt\n",
            "    writing top-level names to gym_fryshome.egg-info/top_level.txt\n",
            "    writing manifest file 'gym_fryshome.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.6/dist-packages/gym-fryshome.egg-link (link to .)\n",
            "    gym-fryshome 0.0.1 is already the active version in easy-install.pth\n",
            "\n",
            "    Installed /content/diec/day4/rl/gym-fryshome\n",
            "Successfully installed gym-fryshome\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-w83an5vv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ITTKEVV_O8",
        "colab_type": "text"
      },
      "source": [
        "## ** Restart the Colab kernel after every pip install**\n",
        "\n",
        "Runtime -> Restart Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zj5DFniQ11y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d31f79c5-c7d1-46e8-df36-80827bb79a4a"
      },
      "source": [
        "# IMPORTANT: RESTART THE COLAB KERNEL if you've just run !pip install\n",
        "\n",
        "# Test the installation\n",
        "import gym_fryshome\n",
        "\n",
        "gym_fryshome"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'gym_fryshome' from '/content/diec/day4/rl/gym-fryshome/gym_fryshome/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2iBf7ZeJgeT",
        "colab_type": "text"
      },
      "source": [
        "## Random Walk Agent\n",
        " \n",
        "The simplest way is to have Bender randomly walk around the house.\n",
        "* We will run 20 episodes, where each episode is a maximum of 100 steps\n",
        "* Refer to http://gym.openai.com/docs/\n",
        "\n",
        "This doesn't actually learn anything, but is a good baseline for any RL agents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLpFOINPf9Br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent:\n",
        "    \"\"\"The world's simplest agent!\n",
        "      https://github.com/openai/gym/blob/master/examples/agents/random_agent.py\n",
        "    \"\"\"\n",
        "    def __init__(self, action_space):\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def act(self, observation, reward, done):\n",
        "        return self.action_space.sample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycXafXEJ-tR",
        "colab_type": "code",
        "outputId": "485e3a71-75f5-4da7-fb3c-3e0d784ba0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "# Constants\n",
        "EPISODE_COUNT = 20\n",
        "STEPS_PER_EPISODE = 100\n",
        "R = np.array([[-1, -1, -1, -1,  0, -1], # action 0\n",
        "              [-1, -1, -1,  0, -1, 0],  # action 1\n",
        "              [-1, -1, -1,  0, -1, -1], # etc\n",
        "              [-1,  0,  0, -1,  0, -1],\n",
        "              [ 0, -1, -1,  0, -1,  0],\n",
        "              [-1, 100, -1, -1, 100, 100]])\n",
        "\n",
        "# Global state\n",
        "done = False\n",
        "reward = 0\n",
        "\n",
        "# Create our environment (Fry's home), and our agent\n",
        "env = gym.make('gym_fryshome:fryshome-v0', rewards=R)\n",
        "bender_agent = RandomAgent(env.action_space)\n",
        "\n",
        "for episode in range(EPISODE_COUNT):\n",
        "  observation = env.reset()\n",
        "\n",
        "  for t in range(STEPS_PER_EPISODE):\n",
        "    env.render()\n",
        "    \n",
        "    # take a random action\n",
        "    action = bender_agent.act(observation, reward, done)\n",
        "\n",
        "    # step the environment using the selected action\n",
        "    observation, reward, done, info = env.step(action)\n",
        "\n",
        "    if done:\n",
        "      print(f'Episode finished after {t+1} timesteps\\n')\n",
        "      done = False # reset for next episode\n",
        "      break\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current room: 4, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 0, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 4, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Current room: 2, Reached goal: False\n",
            "Current room: 3, Reached goal: False\n",
            "Current room: 1, Reached goal: False\n",
            "Episode finished after 8 timesteps\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blqh8_sZbXEW",
        "colab_type": "text"
      },
      "source": [
        "## Q-Learning Agent\n",
        "\n",
        "Let's implement the basic Q-Learning formula (without Temporal Differencing):\n",
        "\n",
        "`Q(state, action) = R(state, action) + gamma * max[Q(next_state, all actions)]`\n",
        "\n",
        "Our Q-Learning agent will store the Q-values as we go along. This can be thought of as Benders \"brain\"!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5D-vv4_cWox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from gym import spaces\n",
        "\n",
        "class QLearningAgent:\n",
        "  \"\"\"Basic Q-Learning Agent\"\"\"\n",
        "  def __init__(self, rewards, gamma=0.8, verbose=False):\n",
        "    \"\"\"rewards: the rewards matrix\n",
        "    gamma: the discount factor in considering future rewards\n",
        "    \"\"\"\n",
        "    self.rewards = rewards\n",
        "\n",
        "    self.action_space = spaces.Discrete(rewards.shape[0])\n",
        "    self.action = self.action_space.sample()\n",
        "\n",
        "    self.actions = np.arange(rewards.shape[0])\n",
        "\n",
        "    self.gamma = gamma\n",
        "    self.verbose = verbose\n",
        "\n",
        "    # Initialise the Q-matrix to zeros:\n",
        "    # dimensions (row=state, cols=actions)\n",
        "    self.Q = np.zeros(rewards.shape)\n",
        "\n",
        "  def _get_valid_actions(self, observation):\n",
        "    return self.actions[self.rewards[observation] != -1]\n",
        "\n",
        "  def act(self, observation, reward, done):\n",
        "    \"\"\"Update the Q-matrix, then take an action\n",
        "    observation: current state\n",
        "    reward: reward from the previous action\n",
        "    done: whether the episode is completed\n",
        "    \"\"\"\n",
        "    if done:\n",
        "      return self.action # no change, we are done\n",
        "\n",
        "    # randomly select the next action (and next observation)\n",
        "    valid_actions = self._get_valid_actions(observation)\n",
        "    self.action = np.random.choice(valid_actions)\n",
        "    next_observation = self.action\n",
        "\n",
        "    # find the maximum reward for all actions given the next observation\n",
        "    all_actions = self._get_valid_actions(next_observation)\n",
        "    future_rewards = self.rewards[next_observation][all_actions]\n",
        "\n",
        "    print(f'Next action/observation: {next_observation}, all actions: \\\n",
        "{all_actions}, all future rewards: {future_rewards}, max future reward: \\\n",
        "{future_rewards.max()}')\n",
        "\n",
        "    # update the Q matrix\n",
        "    self.Q[observation][self.action] = self.rewards[observation][self.action] \\\n",
        "      + self.gamma * future_rewards.max()\n",
        "    if self.verbose:\n",
        "      print(f'Q-values:\\n{self.Q}')\n",
        "\n",
        "    return self.action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_aCvSQRd1WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1ab62ad7-f230-42a1-de8d-fdb3838dea2a"
      },
      "source": [
        "# Unit Test\n",
        "R = np.array([[-1, -1, -1, -1,  0, -1], # action 0\n",
        "              [-1, -1, -1,  0, -1, 0],  # action 1\n",
        "              [-1, -1, -1,  0, -1, -1], # etc\n",
        "              [-1,  0,  0, -1,  0, -1],\n",
        "              [ 0, -1, -1,  0, -1,  0],\n",
        "              [-1, 100, -1, -1, 100, 100]])\n",
        "\n",
        "test_agent = QLearningAgent(rewards=R, verbose=True)\n",
        "test_agent.act(1, 0, False)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Q-values:\n",
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LDllxIHsHkZ",
        "colab_type": "text"
      },
      "source": [
        "Put our agent to work. Hopefully Bender is now smarter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHBprCxpsHBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8c8d4aa-ae44-4b04-f236-361cf264d316"
      },
      "source": [
        "# Global state\n",
        "EPISODE_COUNT = 5000\n",
        "STEPS_PER_EPISODE = 20\n",
        "done = False\n",
        "reward = 0\n",
        "\n",
        "# Track how many timesteps it took to finish\n",
        "history = {start:[] for start in range(R.shape[0])}\n",
        "\n",
        "# Create our environment (Fry's home), and our new agent\n",
        "env = gym.make('gym_fryshome:fryshome-v0', rewards=R)\n",
        "bender_v2 = QLearningAgent(rewards=R)\n",
        "\n",
        "for episode in range(EPISODE_COUNT):\n",
        "  observation = env.reset()\n",
        "  start = observation\n",
        "\n",
        "  for t in range(STEPS_PER_EPISODE):\n",
        "    env.render()\n",
        "    \n",
        "    # take the next action\n",
        "    action = bender_v2.act(observation, reward, done)\n",
        "\n",
        "    # step the environment using the selected action\n",
        "    observation, reward, done, info = env.step(action)\n",
        "\n",
        "    if done:\n",
        "      print(f'Episode finished after {t+1} timesteps\\n')\n",
        "      history[start].append(t)\n",
        "      done = False # reset for next episode\n",
        "      break\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 20 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 20 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 17 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 14 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 15 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 17 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 16 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 12 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 15 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 20 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 17 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 15 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 12 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 16 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 12 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 19 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 14 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 12 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 20 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 11 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 20 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 15 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 12 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 18 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 14 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 15 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 17 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 8 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 15 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 3 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 17 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 20 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 17 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 5, Reached goal: True\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 1 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 4 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 10 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 12 timesteps\n",
            "\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 5 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 9 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 6 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 7 timesteps\n",
            "\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 0, all actions: [4], all future rewards: [0], max future reward: 0\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 2, all actions: [3], all future rewards: [0], max future reward: 0\n",
            "Current room: 2, Reached goal: False\n",
            "Next action/observation: 3, all actions: [1 2 4], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 3, Reached goal: False\n",
            "Next action/observation: 1, all actions: [3 5], all future rewards: [0 0], max future reward: 0\n",
            "Current room: 1, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 13 timesteps\n",
            "\n",
            "Current room: 0, Reached goal: False\n",
            "Next action/observation: 4, all actions: [0 3 5], all future rewards: [0 0 0], max future reward: 0\n",
            "Current room: 4, Reached goal: False\n",
            "Next action/observation: 5, all actions: [1 4 5], all future rewards: [100 100 100], max future reward: 100\n",
            "Episode finished after 2 timesteps\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smpLf_eVuLNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "625913df-03c7-4dad-eb4d-4fcaad42a045"
      },
      "source": [
        "# plot the history as a moving average\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def moving_average(a, n):\n",
        "  # https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpy\n",
        "  ret = np.cumsum(a, dtype=float)\n",
        "  ret[n:] = ret[n:] - ret[:-n]\n",
        "  return ret[n - 1:] / n\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "window_size = 100\n",
        "for start, ts in history.items():\n",
        "  ax.plot(moving_average(ts, window_size), label=f'Starting Room: {start}')\n",
        "\n",
        "ax.set_title(f'Time to find solution')\n",
        "ax.set_xlabel(f'Episodes')\n",
        "ax.set_ylabel(f'Moving average (window size: {window_size})')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAHwCAYAAADeojx9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n51S4iYiIiIiI+JwKNxEREREREZ/7/+WGhFxTl85qAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcVUTk9qHHYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "944167df-5c08-44db-c3aa-ce9a77cb07b7"
      },
      "source": [
        "bender_v2.Q"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,  80.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,  80.],\n",
              "       [  0., 100.,   0.,   0., 100., 180.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV0Y7oSyHKFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iondWqqHKII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkaJhf12dham",
        "colab_type": "text"
      },
      "source": [
        "## More Advanced Agents\n",
        "\n",
        "You can install baselines, which contain implementation of more sophisticated agents.\n",
        "\n",
        "https://github.com/openai/baselines"
      ]
    }
  ]
}