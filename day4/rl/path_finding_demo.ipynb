{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "path_finding_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAzFg9hfPFQXf3P9E4BC5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaong/diec/blob/rl_path_finding/day4/rl/path_finding_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxsIdZTi60PM",
        "colab_type": "text"
      },
      "source": [
        "# Reinforcement Learning Path-Finding Demo\n",
        "\n",
        "This demonstrates how to:\n",
        "- Use OpenAI gym to create a custom environment\n",
        "- Compare different Q-learning algorithms for Reinforcement Learning\n",
        "\n",
        "Inspired by: http://mnemstudio.org/path-finding-q-learning-tutorial.htm\n",
        "\n",
        "## Problem Setup\n",
        "\n",
        "Bender is lost in Fry's house! Help Bender find Fry (who is in Room 5 waiting with a can of beer).\n",
        "\n",
        "![intro](https://github.com/lisaong/diec/raw/rl_path_finding/day4/rl/path_finding_intro.png)\n",
        "\n",
        "## OpenAI Gym\n",
        "\n",
        "[OpenAI Gym](https://gym.openai.com/) is an open-source Python toolkit for developing RL algorithms.\n",
        "\n",
        "We will use OpenAI gym to re-create Fry's house, then run some reinforcement learning to find the path.\n",
        "\n",
        "https://github.com/openai/gym/blob/master/docs/creating-environments.md\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvDQ9PwW6SFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2c8721e-1650-465a-ffe4-345ab8731835"
      },
      "source": [
        "# gym is already built into Colab\n",
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "gym.__version__"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.15.6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GBlQwqV_dSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FrysHomeEnv(gym.Env):\n",
        "  \"\"\"Custom Environment describing Fry's home  \n",
        "  \n",
        "  For details on the gym.Env class:\n",
        "  https://github.com/openai/gym/blob/master/gym/core.py\n",
        "  \"\"\"\n",
        "\n",
        "  # render to the current display or terminal\n",
        "  metadata = {'render.modes': ['human']}\n",
        "\n",
        "  def __init__(self):\n",
        "    super(FrysHomeEnv, self).__init__()\n",
        "\n",
        "    # Initialise the rewards matrix according to the graph above\n",
        "    # Where:\n",
        "    #  state: current room, action: next room\n",
        "    #  dimensions (row=state, col=actions)\n",
        "    #  A value of -1 means there is no adjacent path from room_i to room_j\n",
        "    #  (for example, room_0 to room_0 has, room_0 to room_5)\n",
        "    self.rewards = np.array([[-1, -1, -1, -1,  0, -1], # action 0\n",
        "                             [-1, -1, -1,  0, -1, 0],  # action 1\n",
        "                             [-1, -1, -1,  0, -1, -1], # etc\n",
        "                             [-1,  0,  0, -1,  0, -1],\n",
        "                             [ 0, -1, -1,  0, -1,  0],\n",
        "                             [-1, 100, -1, -1, 100, 100]])\n",
        "    \n",
        "    self.num_rooms = self.rewards.shape[0]\n",
        "\n",
        "    # Action space describes all possible actions that can be taken\n",
        "    # here, we can select 1 out of 6 rooms\n",
        "    self.action_space = spaces.Discrete(self.num_rooms)\n",
        "\n",
        "    # Observation space describes the valid observations\n",
        "    # since we are moving between rooms, we can be in 1 of 6 rooms\n",
        "    self.observation_space = spaces.Discrete(self.num_rooms)\n",
        "\n",
        "    # Rewards range describes the min and max possible rewards\n",
        "    self.reward_range = (self.rewards.min(), self.rewards.max())\n",
        "\n",
        "    # Room 5 is our goal\n",
        "    self.goal = 5\n",
        "\n",
        "    # Initialise our state\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"Reset the environment to an initial state\"\"\"\n",
        "\n",
        "    # Randomly initialise the state\n",
        "    self.state = random.randint(0, self.num_rooms)\n",
        "\n",
        "    # Return the observation (same as the state in our case)\n",
        "    obs = self.state\n",
        "    return obs\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Execute one step within the environment\"\"\"\n",
        "\n",
        "    # take the selected action\n",
        "    prev_state = self.state\n",
        "    self.state = action\n",
        "\n",
        "    # calculate the reward\n",
        "    reward = self.rewards[prev_state][action]\n",
        "\n",
        "    # check if we've reached our goal\n",
        "    done = (self.state == self.goal)\n",
        "\n",
        "    # get the next observation\n",
        "    obs = self.state\n",
        "\n",
        "    return obs, reward, done, {}\n",
        "\n",
        "  def render(self, mode='human', close=True):\n",
        "    print(f'Current room: {self.state}')\n",
        "    print(f'Reached goal: {self.state == self.goal}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyjONcEzEzTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2cafde1a-4ec7-4069-93eb-f0ff58f9cf95"
      },
      "source": [
        "# Unit testing\n",
        "myenv = FrysHomeEnv()\n",
        "\n",
        "for i in range(0, 6):\n",
        "  print(myenv.step(i))\n",
        "  myenv.render()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, -1, False, {})\n",
            "Current room: 0\n",
            "Reached goal: False\n",
            "(1, -1, False, {})\n",
            "Current room: 1\n",
            "Reached goal: False\n",
            "(2, -1, False, {})\n",
            "Current room: 2\n",
            "Reached goal: False\n",
            "(3, 0, False, {})\n",
            "Current room: 3\n",
            "Reached goal: False\n",
            "(4, 0, False, {})\n",
            "Current room: 4\n",
            "Reached goal: False\n",
            "(5, 0, True, {})\n",
            "Current room: 5\n",
            "Reached goal: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ8RA_ilKtkX",
        "colab_type": "text"
      },
      "source": [
        "# Package custom environment as module\n",
        "\n",
        "OpenAI gym requires all environments to be packaged as Python modules.\n",
        "\n",
        "The code above has been packaged here:\n",
        "https://github.com/lisaong/diec/blob/master/day4/rl/gym-fryshome\n",
        "\n",
        "The module follows this convention:\n",
        "https://github.com/openai/gym/blob/master/docs/creating-environments.md"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Og9jdZ_Ist3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Register the environment with OpenAI gym\n",
        "\n",
        "from gym.envs.registration import register\n",
        "register(id='fryshome-v0', entry_point='FooEnv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2iBf7ZeJgeT",
        "colab_type": "text"
      },
      "source": [
        "## Learn using Random Walk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycXafXEJ-tR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "dffa0b6e-403c-42f1-ad7d-02571a5f6a9e"
      },
      "source": [
        "env = gym.make('gym-fryshome:fryshome-v0')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f43b48b7e7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fryshome-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Making new env: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBZ9lWopKCXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}