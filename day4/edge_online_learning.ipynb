{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "edge_online_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisaong/diec/blob/tf2/day4/edge_online_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixHHAaHPV8mf",
        "colab_type": "text"
      },
      "source": [
        "# Edge Online Learning\n",
        "\n",
        "In this notebook, we will train a simple model that will be updated on the device using incoming data.\n",
        "\n",
        "Tensorflow Lite does not support training on device CPU (yet), so we have to use the full version of Tensorflow. The implication is that models should be simple so that incremental training is not prohibitively expensive on the device.\n",
        "\n",
        "1. Train simple model incrementally using Keras (Tensorflow backend)\n",
        "2. Deploy full Tensorflow model on Raspberry Pi 3\n",
        "3. Continue training with incoming data on Raspberry Pi 3\n",
        "\n",
        "The model we will train is a binary classification gesture detector. The gesture data collection is covered separately. This notebook covers the machine learning and deployment portions.\n",
        "\n",
        "The gesture data consists of accelerometer and compass readings collected from the BBC micro:bit. The target is True or False, depending on whether the gesture is happening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BojC5ZoDwNzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUIYxwopRGZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzW3TxWIbyC_",
        "colab_type": "text"
      },
      "source": [
        "## Load initial dataset\n",
        "\n",
        "Upload your data.csv to the Files tab of your Colab session before running the cell below.\n",
        "\n",
        "(Note that you should not put it in the sample_data folder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zolvaByzjhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = './data.csv'\n",
        "\n",
        "df = pd.read_csv(url, names=['Gesture', 'AccX', 'AccY', 'AccZ', 'Heading'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuU8pbDtdZCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert True to 1 and False to 0\n",
        "# in this case we are just converting boolean types\n",
        "# if converting non boolean types, use df['Gesture'].map(...)\n",
        "df['Gesture_enc'] = df['Gesture'].astype('int8')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NyW8ySfcWfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the data, coloured based on whether gesture is recognized\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 8), nrows=2)\n",
        "\n",
        "df[['AccX', 'AccY', 'AccZ', 'Heading']].plot(ax=ax[0])\n",
        "df[['Gesture_enc']].plot(ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny-7wErHcb4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale the data and plot again to see more patterns\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaled_data = scaler.fit_transform(df[['AccX', 'AccY', 'AccZ', 'Heading']])\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_data,\n",
        "                         columns=['AccX_scaled', 'AccY_scaled', 'AccZ_scaled', 'Heading_scaled'])\n",
        "scaled_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-e6pMKMxOj7",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 2: Inspecting the pre-processed data\n",
        "<p>\n",
        "<font color=\"red\">\n",
        "Run the cell below to generate a plot of your gesture data.\n",
        "</font>\n",
        "</p>\n",
        "<p>\n",
        "<font color=\"green\">\n",
        "Submission:\n",
        "Paste your plot into the submission worksheet</li>\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ueun3buAgXAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the data, coloured based on whether gesture is recognized\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 8), nrows=2)\n",
        "\n",
        "scaled_df.plot(ax=ax[0])\n",
        "df[['Gesture_enc']].plot(ax=ax[1])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FllO5eeihQZz",
        "colab_type": "text"
      },
      "source": [
        "## Preparing data for training\n",
        "\n",
        "From the plot above, you should be able to find some consistent patterns that are associated with your gesture. \n",
        "\n",
        "Let's apply windowing so that the past \"window\" of samples will be used for prediction. This is a multi-variate time series dataset.\n",
        "\n",
        "Estimate the width of the patterns to determine what window to use for prediction.\n",
        "\n",
        "Change the `timesteps` parameter to match your window size, for best results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdXqXlfih6Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the time series so that each entry contains a series of timesteps.\n",
        "# Before: rows, features\n",
        "# After: rows, timesteps, features\n",
        "# Note that some rows will be removed because we are taking a window of values.\n",
        "\n",
        "# TODO: Change this to match your gesture width.\n",
        "timesteps = 20\n",
        "\n",
        "# we will use the scaled version of the features\n",
        "print('Before', scaled_df.shape) # (rows, features)\n",
        "\n",
        "rolling_indexes = [(range(i, i+timesteps))\n",
        "                   for i in range(scaled_df.shape[0]-timesteps)]\n",
        "\n",
        "X_sequence = np.take(scaled_df.values, rolling_indexes, axis=0)\n",
        "print('After', X_sequence.shape) # (rows, timesteps, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBACgcg7ib5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute y based on rolling average of window values\n",
        "# make sure y is the same length as X_sequence\n",
        "\n",
        "target = 'Gesture_enc'\n",
        "print('Before', df[target].shape)\n",
        "\n",
        "# rolling average, using numpy to avoid a dependency on pandas\n",
        "# https://stackoverflow.com/questions/13728392/moving-average-or-running-mean\n",
        "y = np.convolve(df[target].values, np.ones((timesteps,))/timesteps, mode='valid')\n",
        "\n",
        "# shift forward by 1\n",
        "y = y[1:]\n",
        "\n",
        "# apply a threshold to convert to 1 and 0\n",
        "y = np.where(y >= 0.5, 1, 0)\n",
        "\n",
        "print('After', y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QuvJ_GN287C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check for imbalance\n",
        "# imbalanced classes will make it harder to train.\n",
        "# Ideally, a 50:50 ratio is preferred. Slightly imbalance is okay, but no more than 5x.\n",
        "plt.hist(y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYkvjRvJi1iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_sequence, y, test_size=0.1,\n",
        "                                                  stratify=y)\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYrwoZL3jI8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualise a sampling of windows\n",
        "\n",
        "n = 5\n",
        "sample_X, sample_y = X_train[:n], y_train[:n]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=n, figsize=(10, 10))\n",
        "plt.subplots_adjust(hspace=1)\n",
        "\n",
        "for i in range(n):\n",
        "  axes[i].plot(sample_X[i])\n",
        "  axes[i].set_title(f'y={sample_y[i]}')\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMvnfQH83NNq",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c9F77lCyez-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input_shape=(timesteps, features)\n",
        "model.add(Conv1D(64, kernel_size=3,\n",
        "                 input_shape=(X_train.shape[1], X_train.shape[2]),\n",
        "                 activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBSrLaNd3icF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meOe64FO3nWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mc = ModelCheckpoint('./cnn_online.h5', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUqJbyBy3qHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_val, y_val), callbacks=[mc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G34RkalM3t4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.plot(history.history['loss'], label='train')\n",
        "ax.plot(history.history['val_loss'], label='val')\n",
        "ax.legend()\n",
        "ax.set_title('Learning curve')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVrVa-aV4MCz",
        "colab_type": "text"
      },
      "source": [
        "## Training from checkpoint\n",
        "\n",
        "We will load a checkpoint of the model and use it for incremental training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-oP8644Zzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the checkpoint\n",
        "checkpoint = load_model('./cnn_online.h5')\n",
        "checkpoint.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LebM-K1W4pvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# continue training for 1 epoch (just to test)\n",
        "history = checkpoint.fit(X_train, y_train, epochs=1,\n",
        "                         validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYOmayIi50YF",
        "colab_type": "text"
      },
      "source": [
        "## Preparing for Deployment\n",
        "\n",
        "We will define/save the following for deployment on a Raspberry Pi:\n",
        "\n",
        "1. Pre-processors: scaler, windowing, rolling average\n",
        "2. Checkpoint\n",
        "3. Validation dataset (for overfitting check)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGRrGxfM6cfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These are actually not pickled, but will be defined on the Raspberry Pi\n",
        "\n",
        "def create_windows(X, timesteps):\n",
        "  \"\"\"convert the time series so that each entry contains a series of timesteps.\n",
        "  Before: rows, features\n",
        "  After: rows, timesteps, features\n",
        "  \"\"\"  \n",
        "  rolling_indexes = [(range(i, i+timesteps))\n",
        "                     for i in range(X.shape[0]-timesteps)]\n",
        "\n",
        "  X_out = np.take(X, rolling_indexes, axis=0)\n",
        "    \n",
        "  return X_out\n",
        "\n",
        "def create_rolling_average(y, timesteps):\n",
        "  \"\"\"compute y based on rolling average of window values\n",
        "  https://stackoverflow.com/questions/13728392/moving-average-or-running-mean\n",
        "  \"\"\"\n",
        "  y_out = np.convolve(y, np.ones((timesteps,))/timesteps, mode='valid')\n",
        "\n",
        "  # shift forward by 1\n",
        "  y_out = y_out[1:]\n",
        "\n",
        "  # apply a threshold to convert to 1 and 0\n",
        "  y_out = np.where(y_out >= 0.5, 1, 0)\n",
        "\n",
        "  return y_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdD7DmWN-M73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save scaler, validation set\n",
        "\n",
        "for_training = {\n",
        "    'scaler': scaler,\n",
        "    'X_val': X_val,\n",
        "    'y_val': y_val\n",
        "}\n",
        "\n",
        "pickle.dump(for_training, open('./preprocessors_and_data.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiHi0zAs_iQv",
        "colab_type": "text"
      },
      "source": [
        "### Testing deployment artifacts\n",
        "\n",
        "The following script samples some test data and ensures that the checkpoint can still be trained incrementally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc-2JEDv_zze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset again, picking the last 2*window_size samples\n",
        "df_test = pd.read_csv(url, names=['Gesture', 'AccX', 'AccY', 'AccZ', 'Heading'])\n",
        "\n",
        "sample = df_test.iloc[-(timesteps*2):]\n",
        "sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfvfXSnAXU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_sample = np.where(sample['Gesture'], 1, 0)\n",
        "y_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ0LWbxtAu4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_sample = sample.loc[:, sample.columns != 'Gesture'].values\n",
        "X_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qy-kCc6BAw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for_training1 = pickle.load(open('./preprocessors_and_data.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djGXWrTABXCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_sample_scaled = for_training1['scaler'].transform(X_sample)\n",
        "X_sample_train = create_windows(X_sample_scaled, timesteps)\n",
        "y_sample_train = create_rolling_average(y_sample, timesteps)\n",
        "\n",
        "X_sample_train.shape, y_sample_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrfwvrW-Bp42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# continue training with sample data (just to test)\n",
        "# use the original validation data\n",
        "checkpoint.fit(X_sample_train, y_sample_train, epochs=1,\n",
        "               validation_data=(for_training1['X_val'], for_training1['y_val']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GghGjwUnEeLh",
        "colab_type": "text"
      },
      "source": [
        "We are now ready to deploy on the Raspberry Pi for online training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPnOcjI2EgZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}